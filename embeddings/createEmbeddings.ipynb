{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U cohere pinecone-client datasets\n",
    "!pip3 install python-dotenv\n",
    "!pip3 install cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cohere\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from datasets import Dataset\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "cohereAPIkey = os.getenv('cohereAPIKey')\n",
    "pineconeAPIkey = os.getenv('pineconeAPIKey')\n",
    "\n",
    "co = cohere.Client(cohereAPIkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_dataset = Dataset.from_csv('mh_chatbotQnA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into halves because cohere only taken in 96 \n",
    "mh_dataset_one = mh_dataset.select(range(60))\n",
    "mh_dataset_two = mh_dataset.select(range(60, 119))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddings(dataset):\n",
    "    embeds = co.embed(\n",
    "        texts= dataset,\n",
    "        model='embed-english-v3.0',\n",
    "        input_type='search_document',\n",
    "        truncate='END'\n",
    "    ).embeddings\n",
    "\n",
    "    return embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds_one = getEmbeddings(mh_dataset_one['Question'])\n",
    "embeds_two = getEmbeddings(mh_dataset_two['Question'])\n",
    "\n",
    "total_embeds = embeds_one + embeds_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 1024)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "shape = np.array(total_embeds).shape\n",
    "print(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=pineconeAPIkey)\n",
    "\n",
    "# Name can contain only lowercase letters, numbers and hyphens\n",
    "index_name = 'mentalhealth-embeddings'\n",
    "\n",
    "# if the index does not exist, we create it\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=shape[1],\n",
    "        metric='cosine',\n",
    "        spec=PodSpec(\n",
    "            environment=\"gcp-starter\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# # connect to index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "ids = [str(i) for i in range(shape[0])]\n",
    "# create list of metadata dictionaries\n",
    "meta = [{'question': question, 'answer': answer} for question, answer in zip(mh_dataset['Question'], mh_dataset['Answer'])]\n",
    "\n",
    "# create list of (id, vector, metadata) tuples to be upserted\n",
    "to_upsert = list(zip(ids, total_embeds, meta))\n",
    "\n",
    "for i in range(0, shape[0], batch_size):\n",
    "    i_end = min(i+batch_size, shape[0])\n",
    "    index.upsert(vectors=to_upsert[i:i_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024)\n",
      "0.47: What services are provided at no cost to currently registered GVSU students?\n"
     ]
    }
   ],
   "source": [
    "query = \"what are some services I can get for free?\"\n",
    "\n",
    "# create the query embedding\n",
    "xq = co.embed(\n",
    "    texts=[query],\n",
    "    model='embed-english-v3.0',\n",
    "    input_type='search_query',\n",
    "    truncate='END'\n",
    ").embeddings\n",
    "\n",
    "print(np.array(xq).shape)\n",
    "\n",
    "# query, returning the top 5 most similar results\n",
    "res = index.query(vector=xq, top_k=1, include_metadata=True)\n",
    "\n",
    "for match in res['matches']:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']['question']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
